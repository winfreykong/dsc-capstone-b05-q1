{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263ec265",
   "metadata": {},
   "source": [
    "# Source: \n",
    "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934767ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.distributions.laplace import Laplace\n",
    "from model import DDPM\n",
    "from model import MyTinyUNet\n",
    "from etl import show_images\n",
    "from etl import generate_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c2e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6b38c",
   "metadata": {},
   "source": [
    "The `MyTinyUNet` is a versy small implementation of a convolutional UNet where a time embedding has been added at each step. To make things simple, we need to have an image of size $s\\times s$ with $s$ divisible by 8 (this is why we will increase the size of the MNIST dataset from $28\\times 28$ to $32 \\times 32$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71d57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 3\n",
    "x = torch.randn(bs,1,32,32)\n",
    "n_steps=1000\n",
    "timesteps = torch.randint(0, n_steps, (bs,)).long()\n",
    "unet = MyTinyUNet(in_c =1, out_c =1, size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1762df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = unet(x,timesteps)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0fee16",
   "metadata": {},
   "source": [
    "Laplace distribution pdf: $f(x|\\mu , b) = \\frac{1}{2b} \\exp(-\\frac{|x-\\mu|}{b})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a033d",
   "metadata": {},
   "source": [
    "Laplace negative log likelihood: $NLL=\\frac{1}{N}​\\sum_{i=1}^{n}​log(2b)+\\frac{|x_i-\\mu|}{b}$ where b is the scale of Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c4c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceNLL(nn.Module):\n",
    "    def __init__(self, scale = 1.0):\n",
    "        super(LaplaceNLL, self).__init__()\n",
    "        self.scale = scale\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        log = torch.log(torch.tensor([2*self.scale])).to(device)\n",
    "        nll_loss = torch.sum(log + torch.abs(input-target)/self.scale, dim=-1)\n",
    "        nll_loss = torch.mean(nll_loss)\n",
    "        return nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dea59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(noise_distribution, batch, params=None):\n",
    "    noise_distribution_allowed = {\"Gaussian\", \"Laplace\", \"S&P\"}\n",
    "    if noise_distribution not in noise_distribution_allowed:\n",
    "        raise Exception(f\"'noise_distribution' not of value {noise_distribution_allowed}\")\n",
    "    \n",
    "    if noise_distribution == \"Gaussian\":\n",
    "        # normal gaussian, a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 \n",
    "        noise = torch.randn(batch.shape).to(device)\n",
    "        \n",
    "    elif noise_distribution == \"Laplace\":\n",
    "        if params:\n",
    "            loc = param['loc']\n",
    "            scale = param['scale']\n",
    "        else:\n",
    "            # default laplace with loc 0 and scale 1\n",
    "            loc = 0.0\n",
    "            scale = 1.0\n",
    "        noise = Laplace(torch.tensor([loc]), torch.tensor([scale])).expand(batch.shape).sample().to(device)\n",
    "    \n",
    "    elif noise_distribution == \"S&P\":\n",
    "        salt_mask = torch.randn(batch.shape) < 0.01\n",
    "        pepper_mask = (torch.randn(batch.shape) < 0.01) & ~salt_mask # so that we select spot that salt hasn't been added to\n",
    "        noise = (salt_mask.float() + pepper_mask.float()*-1).to(device)\n",
    "        \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27040c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(loss_f, pred, actual):\n",
    "    \n",
    "    if loss_f == \"LaplaceNLL\":\n",
    "        criterion = LaplaceNLL()\n",
    "    elif loss_f == \"L1\":\n",
    "        criterion = nn.L1Loss()\n",
    "    elif loss_f == \"MSE\":\n",
    "        criterion = nn.MSELoss()\n",
    "    \n",
    "    loss = criterion(pred, actual)\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4f6222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, dataloader, optimizer, num_epochs, num_timesteps, device=device, noise=\"Gaussian\", loss_f=\"MSE\"):\n",
    "    \"\"\"Training loop for DDPM\"\"\"\n",
    "\n",
    "    global_step = 0\n",
    "    losses = []\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # what does this do? train() is built-in?\n",
    "        progress_bar = tqdm(total=len(dataloader))\n",
    "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            # put batch to device (gpu or cpu) to leverage computational resources\n",
    "            batch = batch[0].to(device) # batch.shape = torch.Size([4096, 1, 32, 32])\n",
    "            \n",
    "            # create noise\n",
    "            actual_noise = generate_noise(noise, batch)\n",
    "            \n",
    "            # Generates random timesteps for each sample in the batch. \n",
    "            # These timesteps determine at which diffusion step the noise is added. \n",
    "            # The num_timesteps parameter specifies the total number of diffusion steps.\n",
    "            timesteps = torch.randint(0, num_timesteps, (batch.shape[0], )).long().to(device)\n",
    "            \n",
    "            # returns x_{t+1}, a noisy image\n",
    "            noisy = model.add_noise(batch, actual_noise, timesteps)\n",
    "            \n",
    "            # gives the noisy image and returns a prediction of the noise added\n",
    "            noise_pred = model.reverse(noisy, timesteps) # torch.Size([4096, 1, 32, 32])\n",
    "            \n",
    "            loss = calc_loss(loss_f, noise_pred, actual_noise)\n",
    "            \n",
    "            # reset the gradient to zero before computing the new gradient in the backward pass\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Computes the gradients of the loss with respect to the model parameters. \n",
    "            # These gradients are used to update the model weights during optimization.\n",
    "            loss.backward()\n",
    "            \n",
    "            # updates the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            logs = {\"loss\": loss.detach().item(), \"step\": global_step}\n",
    "            losses.append(loss.detach().item())\n",
    "            progress_bar.set_postfix(**logs)\n",
    "            global_step += 1\n",
    "        \n",
    "        progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ab06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './data/'\n",
    "transform01 = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(32),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5), (0.5))\n",
    "    ])\n",
    "dataset = torchvision.datasets.MNIST(root=root_dir, train=True, transform=transform01, download=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=4096, shuffle=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9c619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52bfc48",
   "metadata": {},
   "source": [
    "# Running DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 50\n",
    "num_timesteps = 50\n",
    "network = MyTinyUNet()\n",
    "network = network.to(device)\n",
    "model = DDPM(network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(model, dataloader, optimizer, num_epochs, num_timesteps, device=device, loss_f=\"L1\", noise=\"Laplace\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac7e7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated, generated_mid = generate_image(model, 100, 1, 32, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that generated and generated_mid are list object\n",
    "len(generated), len(generated_mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d231ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_images(generated_mid, \"Mid result\")\n",
    "show_images(generated, \"Final result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b0c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(bn, \"origin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99275f0a",
   "metadata": {},
   "source": [
    "# Aside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8479b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for b in dataloader:\n",
    "    batch = b[0]\n",
    "    what_is_b = b # b[0] is the image tensor, b[1] is the label\n",
    "    break\n",
    "\n",
    "print(batch.shape)\n",
    "bn = [b for b in batch[:100]] # taking first 100 images from the pool of images - total 4096 images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a051ff",
   "metadata": {},
   "source": [
    "### Testing salt & pepper noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432eedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bn[0].permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_mask = torch.rand_like(bn[0]) < 0.01\n",
    "pepper_mask = (torch.rand_like(bn[0]) < 0.01) & ~salt_mask # so that we select spot that salt hasn't been added to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_mask_num = salt_mask.float()\n",
    "pepper_mask_num = pepper_mask.float()*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c17755",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_mask_num + pepper_mask_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef140389",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = bn[0].clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a275476",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[salt_mask] = 1\n",
    "test[pepper_mask] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36736148",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test.permute(1,2,0).numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4172ef51",
   "metadata": {},
   "source": [
    "#### Testing LaplaceNLL class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ee8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_noise1 = Laplace(torch.tensor([0.0]), torch.tensor([2.0])).expand(batch.shape).sample().to(device)\n",
    "laplace_noise2 = Laplace(torch.tensor([0.0]), torch.tensor([2.0])).expand(batch.shape).sample().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5333a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.log(torch.tensor([100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "LaplaceNLL()(laplace_noise1, laplace_noise2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa68922",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.L1Loss()(laplace_noise1, laplace_noise2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb057523",
   "metadata": {},
   "source": [
    "You can check that all the parameters of the UNet `network` are indeed parameters of the DDPM `model` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note how the first size has changed to the new timesteps defined above, which is great\n",
    "for n, p in model.named_parameters():\n",
    "    print(n, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d3a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check memory usage\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like repeated timesteps are allowed?\n",
    "timesteps = torch.randint(0, num_timesteps, (batch.shape[0], )).long().to(device) \n",
    "timesteps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0791a15e",
   "metadata": {},
   "source": [
    "#### Why do we allow repeated timesteps?\n",
    "\n",
    "Allowing repeated timesteps in the same batch is a common practice in various machine learning scenarios. It introduces additional stochasticity into the training process, which can help the model generalize better to different data patterns. Each sample in the batch effectively experiences a different diffusion process, adding diversity to the training data and encouraging the model to learn a more robust representation of the underlying data distribution.\n",
    "\n",
    "In the context of the Denoising Diffusion Probabilistic Model (DDPM), allowing repeated timesteps helps the model learn to handle different diffusion steps for different samples in the same batch, simulating the stochastic nature of the diffusion process in real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2773e6a",
   "metadata": {},
   "source": [
    "### Random stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c357f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(4.)\n",
    "b = a.reshape(-1, 1, 1, 1)\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd6a37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = torch.arange(4.)\n",
    "b = a.reshape(-1, 2, 2, 1)\n",
    "b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a750a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(4.)\n",
    "b = torch.arange(4.)\n",
    "((a+1)/(b+1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6075cbde",
   "metadata": {},
   "source": [
    "The commands below are here to help you and to test your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a730dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 1000\n",
    "betas = torch.linspace(0.0001, 0.02, num_timesteps, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6d13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb53159",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ce5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas[timesteps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9905682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47645019",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas[timesteps].reshape(-1,1,1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c69328",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = MyTinyUNet(in_c =1, out_c =1, size=32)\n",
    "model = DDPM(network, num_timesteps, beta_start=0.0001, beta_end=0.02, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b71af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 5\n",
    "x = torch.randn(bs,1,32,32).to(device)\n",
    "timesteps = 10*torch.ones(bs,).long().long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90480e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac7fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.add_noise(x,x,timesteps)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d92db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.step(x,timesteps[0],x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab1653",
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_noise = Laplace(torch.tensor([0.0]), torch.tensor([1.0])).expand(torch.Size([4096, 1, 32, 32]))\n",
    "laplace_noise.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2163a90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noise = torch.randn(torch.Size([4096, 1, 32, 32]))\n",
    "noise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
